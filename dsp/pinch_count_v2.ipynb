{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinch Detection V2 - Robust Z-Score Fusion Algorithm\n",
    "\n",
    "This notebook implements the advanced pinch detection algorithm based on robust statistics and multi-sensor fusion.\n",
    "\n",
    "## Architecture Overview\n",
    "- **Multi-sensor fusion**: Combine accelerometer and gyroscope signals\n",
    "- **Robust statistics**: Use median/MAD instead of mean/std for noise resilience\n",
    "- **Adaptive thresholding**: Dynamic threshold based on signal characteristics\n",
    "- **Two-sensor gating**: Require both accel and gyro activation\n",
    "- **Refractory period**: Prevent double-counting\n",
    "\n",
    "## Key Parameters (from analysis)\n",
    "- Sampling rate: ~100 Hz\n",
    "- HP window: 0.5s moving mean\n",
    "- Gates: acc_hp ≥ 0.04g, gyro_mag ≥ 0.15 rad/s\n",
    "- Score threshold: median + 7×MAD\n",
    "- Refractory: 250ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Pinch Detection V2 - Loaded successfully\")\n",
    "print(\"Based on robust z-score fusion architecture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "Load wrist motion data and extract key signals:\n",
    "- userAcceleration (already gravity-compensated)\n",
    "- rotationRate (gyroscope)\n",
    "- Compute magnitudes and derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wrist_data(filepath):\n",
    "    \"\"\"Load and preprocess wrist motion data\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(f\"Loaded {len(df)} samples from {filepath}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Extract time and calculate sampling rate\n",
    "    t = df['time'].values\n",
    "    dt = np.median(np.diff(t))\n",
    "    fs = 1.0 / dt\n",
    "    print(f\"Sampling rate: {fs:.1f} Hz\")\n",
    "    print(f\"Duration: {t[-1] - t[0]:.2f} s\")\n",
    "    \n",
    "    # Extract acceleration and gyroscope signals\n",
    "    # Note: Using accelerationX/Y/Z for now, but userAcceleration is preferred\n",
    "    acc_cols = ['accelerationX', 'accelerationY', 'accelerationZ']\n",
    "    gyro_cols = ['rotationRateX', 'rotationRateY', 'rotationRateZ']\n",
    "    \n",
    "    acc_xyz = df[acc_cols].values\n",
    "    gyro_xyz = df[gyro_cols].values\n",
    "    \n",
    "    # Compute magnitudes\n",
    "    acc_mag = np.sqrt(np.sum(acc_xyz**2, axis=1))\n",
    "    gyro_mag = np.sqrt(np.sum(gyro_xyz**2, axis=1))\n",
    "    \n",
    "    return {\n",
    "        'time': t,\n",
    "        'fs': fs,\n",
    "        'acc_xyz': acc_xyz,\n",
    "        'gyro_xyz': gyro_xyz,\n",
    "        'acc_mag': acc_mag,\n",
    "        'gyro_mag': gyro_mag,\n",
    "        'df': df\n",
    "    }\n",
    "\n",
    "# Load the data\n",
    "DATA_PATH = \"~/Downloads/WristMotion.csv\"\n",
    "data = load_wrist_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Statistics Functions\n",
    "\n",
    "Implement robust statistics for noise-resilient signal processing:\n",
    "- Median Absolute Deviation (MAD)\n",
    "- Robust z-scores\n",
    "- Running statistics for real-time processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_mad(x, axis=None, constant=1.4826):\n",
    "    \"\"\"Compute Median Absolute Deviation (MAD)\"\"\"\n",
    "    median = np.median(x, axis=axis, keepdims=True)\n",
    "    mad = np.median(np.abs(x - median), axis=axis) * constant\n",
    "    return mad\n",
    "\n",
    "def robust_zscore(x, window_size=None):\n",
    "    \"\"\"Compute robust z-scores using median and MAD\"\"\"\n",
    "    if window_size is None:\n",
    "        # Global statistics\n",
    "        median = np.median(x)\n",
    "        mad = robust_mad(x)\n",
    "        mad = np.maximum(mad, 1e-6)  # Prevent division by zero\n",
    "        return (x - median) / mad\n",
    "    else:\n",
    "        # Rolling statistics\n",
    "        z_scores = np.zeros_like(x)\n",
    "        for i in range(len(x)):\n",
    "            start = max(0, i - window_size + 1)\n",
    "            end = i + 1\n",
    "            window = x[start:end]\n",
    "            if len(window) > 1:\n",
    "                median = np.median(window)\n",
    "                mad = robust_mad(window)\n",
    "                mad = max(mad, 1e-6)\n",
    "                z_scores[i] = (x[i] - median) / mad\n",
    "        return z_scores\n",
    "\n",
    "def running_percentile(x, window_size, percentile=95):\n",
    "    \"\"\"Compute running percentile for adaptive thresholding\"\"\"\n",
    "    result = np.zeros_like(x)\n",
    "    for i in range(len(x)):\n",
    "        start = max(0, i - window_size + 1)\n",
    "        end = i + 1\n",
    "        window = x[start:end]\n",
    "        result[i] = np.percentile(window, percentile)\n",
    "    return result\n",
    "\n",
    "print(\"Robust statistics functions implemented\")\n",
    "print(\"- robust_mad(): Median Absolute Deviation\")\n",
    "print(\"- robust_zscore(): Robust z-scores with optional rolling window\")\n",
    "print(\"- running_percentile(): Adaptive percentile computation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal Processing Pipeline\n",
    "\n",
    "Implement the core signal processing steps:\n",
    "1. High-pass filtering to remove drift\n",
    "2. Derivative computation\n",
    "3. Robust z-score normalization\n",
    "4. Score fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_pass_filter(x, fs, window_size=0.5):\n",
    "    \"\"\"Remove low-frequency drift using moving average subtraction\"\"\"\n",
    "    window_samples = int(window_size * fs)\n",
    "    # Create moving average\n",
    "    ma = np.convolve(x, np.ones(window_samples)/window_samples, mode='same')\n",
    "    # Subtract to get high-pass effect\n",
    "    return x - ma\n",
    "\n",
    "def compute_derivative(x, fs):\n",
    "    \"\"\"Compute time derivative using finite differences\"\"\"\n",
    "    dt = 1.0 / fs\n",
    "    # Use central differences where possible\n",
    "    dx = np.gradient(x, dt)\n",
    "    return dx\n",
    "\n",
    "def process_signals(data, hp_window=0.5, zscore_window=None):\n",
    "    \"\"\"Process raw signals through the full pipeline\"\"\"\n",
    "    fs = data['fs']\n",
    "    acc_mag = data['acc_mag']\n",
    "    gyro_mag = data['gyro_mag']\n",
    "    \n",
    "    print(f\"Processing signals with fs={fs:.1f} Hz\")\n",
    "    \n",
    "    # Step 1: High-pass filter accelerometer to remove residual gravity/drift\n",
    "    acc_hp = high_pass_filter(acc_mag, fs, hp_window)\n",
    "    print(f\"Applied high-pass filter (window={hp_window}s)\")\n",
    "    \n",
    "    # Step 2: Compute derivatives (jerk-like terms)\n",
    "    acc_deriv = compute_derivative(acc_hp, fs)\n",
    "    gyro_deriv = compute_derivative(gyro_mag, fs)\n",
    "    print(\"Computed derivatives\")\n",
    "    \n",
    "    # Step 3: Compute robust z-scores\n",
    "    if zscore_window is not None:\n",
    "        window_samples = int(zscore_window * fs)\n",
    "        z_acc = robust_zscore(acc_hp, window_samples)\n",
    "        z_gyro = robust_zscore(gyro_mag, window_samples)\n",
    "        z_acc_deriv = robust_zscore(acc_deriv, window_samples)\n",
    "        z_gyro_deriv = robust_zscore(gyro_deriv, window_samples)\n",
    "        print(f\"Computed robust z-scores (rolling window={zscore_window}s)\")\n",
    "    else:\n",
    "        z_acc = robust_zscore(acc_hp)\n",
    "        z_gyro = robust_zscore(gyro_mag)\n",
    "        z_acc_deriv = robust_zscore(acc_deriv)\n",
    "        z_gyro_deriv = robust_zscore(gyro_deriv)\n",
    "        print(\"Computed robust z-scores (global)\")\n",
    "    \n",
    "    # Step 4: Clamp negative values (ignore negative-direction noise)\n",
    "    z_acc_pos = np.maximum(z_acc, 0)\n",
    "    z_gyro_pos = np.maximum(z_gyro, 0)\n",
    "    z_acc_deriv_pos = np.maximum(z_acc_deriv, 0)\n",
    "    z_gyro_deriv_pos = np.maximum(z_gyro_deriv, 0)\n",
    "    \n",
    "    # Step 5: Compute fusion score\n",
    "    score = np.sqrt(z_acc_pos**2 + z_gyro_pos**2 + \n",
    "                   z_acc_deriv_pos**2 + z_gyro_deriv_pos**2)\n",
    "    print(\"Computed fusion score\")\n",
    "    \n",
    "    return {\n",
    "        'acc_hp': acc_hp,\n",
    "        'gyro_mag': gyro_mag,\n",
    "        'acc_deriv': acc_deriv,\n",
    "        'gyro_deriv': gyro_deriv,\n",
    "        'z_acc': z_acc,\n",
    "        'z_gyro': z_gyro,\n",
    "        'z_acc_deriv': z_acc_deriv,\n",
    "        'z_gyro_deriv': z_gyro_deriv,\n",
    "        'score': score\n",
    "    }\n",
    "\n",
    "# Process the signals\n",
    "processed = process_signals(data, hp_window=0.5, zscore_window=2.0)\n",
    "print(f\"\\nSignal processing complete!\")\n",
    "print(f\"Score range: {processed['score'].min():.2f} to {processed['score'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Detection Algorithm\n",
    "\n",
    "Implement the complete detection pipeline:\n",
    "1. Adaptive thresholding\n",
    "2. Two-sensor gating\n",
    "3. Refractory period\n",
    "4. Duration constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PinchDetector:\n",
    "    def __init__(self, fs, acc_gate=0.04, gyro_gate=0.15, \n",
    "                 threshold_method='mad', threshold_k=7,\n",
    "                 refractory_ms=250, min_duration_ms=20, max_duration_ms=200,\n",
    "                 adaptive_window=2.0):\n",
    "        \"\"\"\n",
    "        Pinch detection algorithm with adaptive thresholding and multi-sensor gating\n",
    "        \n",
    "        Parameters:\n",
    "        - fs: sampling rate (Hz)\n",
    "        - acc_gate: minimum acceleration threshold (g)\n",
    "        - gyro_gate: minimum gyroscope threshold (rad/s)\n",
    "        - threshold_method: 'mad' or 'percentile'\n",
    "        - threshold_k: multiplier for MAD-based threshold\n",
    "        - refractory_ms: minimum time between events (ms)\n",
    "        - min/max_duration_ms: event duration constraints (ms)\n",
    "        - adaptive_window: window for adaptive threshold (s)\n",
    "        \"\"\"\n",
    "        self.fs = fs\n",
    "        self.acc_gate = acc_gate\n",
    "        self.gyro_gate = gyro_gate\n",
    "        self.threshold_method = threshold_method\n",
    "        self.threshold_k = threshold_k\n",
    "        self.refractory_samples = int(refractory_ms * fs / 1000)\n",
    "        self.min_duration_samples = int(min_duration_ms * fs / 1000)\n",
    "        self.max_duration_samples = int(max_duration_ms * fs / 1000)\n",
    "        self.adaptive_window_samples = int(adaptive_window * fs)\n",
    "        \n",
    "        print(f\"PinchDetector initialized:\")\n",
    "        print(f\"  Sampling rate: {fs:.1f} Hz\")\n",
    "        print(f\"  Gates: acc≥{acc_gate:.3f}g, gyro≥{gyro_gate:.3f}rad/s\")\n",
    "        print(f\"  Threshold: {threshold_method} (k={threshold_k})\")\n",
    "        print(f\"  Refractory: {refractory_ms}ms ({self.refractory_samples} samples)\")\n",
    "        print(f\"  Duration: {min_duration_ms}-{max_duration_ms}ms\")\n",
    "    \n",
    "    def compute_adaptive_threshold(self, score):\n",
    "        \"\"\"Compute adaptive threshold based on signal statistics\"\"\"\n",
    "        if self.threshold_method == 'percentile':\n",
    "            threshold = running_percentile(score, self.adaptive_window_samples, 95)\n",
    "        else:  # MAD-based\n",
    "            threshold = np.zeros_like(score)\n",
    "            for i in range(len(score)):\n",
    "                start = max(0, i - self.adaptive_window_samples + 1)\n",
    "                end = i + 1\n",
    "                window = score[start:end]\n",
    "                if len(window) > 10:  # Need enough samples for robust stats\n",
    "                    median = np.median(window)\n",
    "                    mad = robust_mad(window)\n",
    "                    threshold[i] = median + self.threshold_k * mad\n",
    "                else:\n",
    "                    threshold[i] = np.percentile(score[:end], 90)  # Fallback\n",
    "        \n",
    "        return threshold\n",
    "    \n",
    "    def detect_events(self, processed_signals):\n",
    "        \"\"\"Detect pinch events using the full algorithm\"\"\"\n",
    "        score = processed_signals['score']\n",
    "        acc_hp = processed_signals['acc_hp']\n",
    "        gyro_mag = processed_signals['gyro_mag']\n",
    "        \n",
    "        # Step 1: Compute adaptive threshold\n",
    "        threshold = self.compute_adaptive_threshold(score)\n",
    "        \n",
    "        # Step 2: Find candidate peaks\n",
    "        above_threshold = score > threshold\n",
    "        \n",
    "        # Step 3: Apply two-sensor gating\n",
    "        acc_gate_met = acc_hp > self.acc_gate\n",
    "        gyro_gate_met = gyro_mag > self.gyro_gate\n",
    "        valid_candidates = above_threshold & acc_gate_met & gyro_gate_met\n",
    "        \n",
    "        # Step 4: Find event boundaries and apply duration constraints\n",
    "        events = []\n",
    "        last_event_end = -self.refractory_samples\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(valid_candidates):\n",
    "            if valid_candidates[i] and i > (last_event_end + self.refractory_samples):\n",
    "                # Find start of event\n",
    "                start = i\n",
    "                while start > 0 and score[start-1] > threshold[start-1] * 0.5:\n",
    "                    start -= 1\n",
    "                \n",
    "                # Find end of event\n",
    "                end = i\n",
    "                while end < len(score)-1 and score[end+1] > threshold[end+1] * 0.5:\n",
    "                    end += 1\n",
    "                \n",
    "                duration = end - start + 1\n",
    "                \n",
    "                # Apply duration constraints\n",
    "                if self.min_duration_samples <= duration <= self.max_duration_samples:\n",
    "                    # Find peak within event\n",
    "                    peak_idx = start + np.argmax(score[start:end+1])\n",
    "                    \n",
    "                    event = {\n",
    "                        'peak_idx': peak_idx,\n",
    "                        'start_idx': start,\n",
    "                        'end_idx': end,\n",
    "                        'duration_samples': duration,\n",
    "                        'peak_score': score[peak_idx],\n",
    "                        'peak_acc': acc_hp[peak_idx],\n",
    "                        'peak_gyro': gyro_mag[peak_idx],\n",
    "                        'threshold_at_peak': threshold[peak_idx]\n",
    "                    }\n",
    "                    events.append(event)\n",
    "                    last_event_end = end\n",
    "                \n",
    "                i = end + 1\n",
    "            else:\n",
    "                i += 1\n",
    "        \n",
    "        # Add timing information\n",
    "        for event in events:\n",
    "            event['peak_time'] = event['peak_idx'] / self.fs\n",
    "            event['duration_ms'] = (event['duration_samples'] / self.fs) * 1000\n",
    "        \n",
    "        print(f\"\\nEvent detection complete:\")\n",
    "        print(f\"  {len(events)} events detected\")\n",
    "        print(f\"  Threshold range: {threshold.min():.2f} to {threshold.max():.2f}\")\n",
    "        \n",
    "        return events, threshold\n",
    "\n",
    "# Initialize detector with analysis-based parameters\n",
    "detector = PinchDetector(\n",
    "    fs=data['fs'],\n",
    "    acc_gate=0.04,      # 0.04g from analysis\n",
    "    gyro_gate=0.15,     # 0.15 rad/s from analysis\n",
    "    threshold_k=7,      # median + 7*MAD from analysis\n",
    "    refractory_ms=250,  # 250ms from analysis\n",
    "    adaptive_window=2.0 # 2s adaptive window\n",
    ")\n",
    "\n",
    "# Detect events\n",
    "events, threshold = detector.detect_events(processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization and Analysis\n",
    "\n",
    "Visualize the detection results and analyze performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_detection_results(data, processed, events, threshold):\n",
    "    \"\"\"Create comprehensive visualization of detection results\"\"\"\n",
    "    t = data['time']\n",
    "    \n",
    "    # Convert events to arrays for plotting\n",
    "    if events:\n",
    "        event_times = [e['peak_time'] for e in events]\n",
    "        event_scores = [e['peak_score'] for e in events]\n",
    "        event_accs = [e['peak_acc'] for e in events]\n",
    "        event_gyros = [e['peak_gyro'] for e in events]\n",
    "    else:\n",
    "        event_times = event_scores = event_accs = event_gyros = []\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 1, figsize=(14, 12))\n",
    "    \n",
    "    # Plot 1: Score and threshold\n",
    "    axes[0].plot(t, processed['score'], 'b-', linewidth=0.8, label='Fusion Score')\n",
    "    axes[0].plot(t, threshold, 'r--', linewidth=1.0, label='Adaptive Threshold')\n",
    "    if event_times:\n",
    "        axes[0].scatter(event_times, event_scores, c='red', s=50, zorder=5, label=f'Events ({len(events)})')\n",
    "    axes[0].set_ylabel('Score')\n",
    "    axes[0].set_title('Fusion Score with Adaptive Threshold and Detected Events')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: High-pass accelerometer\n",
    "    axes[1].plot(t, processed['acc_hp'], 'g-', linewidth=0.8, label='HP Acceleration')\n",
    "    axes[1].axhline(y=detector.acc_gate, color='orange', linestyle='--', alpha=0.7, label=f'Gate: {detector.acc_gate:.3f}g')\n",
    "    if event_times:\n",
    "        axes[1].scatter(event_times, event_accs, c='red', s=50, zorder=5)\n",
    "    axes[1].set_ylabel('Acceleration (g)')\n",
    "    axes[1].set_title('High-Pass Filtered Acceleration Magnitude')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Gyroscope\n",
    "    axes[2].plot(t, processed['gyro_mag'], 'm-', linewidth=0.8, label='Gyro Magnitude')\n",
    "    axes[2].axhline(y=detector.gyro_gate, color='orange', linestyle='--', alpha=0.7, label=f'Gate: {detector.gyro_gate:.3f}rad/s')\n",
    "    if event_times:\n",
    "        axes[2].scatter(event_times, event_gyros, c='red', s=50, zorder=5)\n",
    "    axes[2].set_ylabel('Angular Rate (rad/s)')\n",
    "    axes[2].set_title('Gyroscope Magnitude')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Z-scores\n",
    "    axes[3].plot(t, processed['z_acc'], 'g-', alpha=0.7, linewidth=0.6, label='Z-score Acc')\n",
    "    axes[3].plot(t, processed['z_gyro'], 'm-', alpha=0.7, linewidth=0.6, label='Z-score Gyro')\n",
    "    axes[3].plot(t, processed['z_acc_deriv'], 'c-', alpha=0.7, linewidth=0.6, label='Z-score Acc Deriv')\n",
    "    axes[3].plot(t, processed['z_gyro_deriv'], 'y-', alpha=0.7, linewidth=0.6, label='Z-score Gyro Deriv')\n",
    "    axes[3].set_ylabel('Z-score')\n",
    "    axes[3].set_xlabel('Time (s)')\n",
    "    axes[3].set_title('Individual Z-scores')\n",
    "    axes[3].legend()\n",
    "    axes[3].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_events(events, data):\n",
    "    \"\"\"Analyze detected events and print statistics\"\"\"\n",
    "    if not events:\n",
    "        print(\"No events detected!\")\n",
    "        return\n",
    "    \n",
    "    # Basic statistics\n",
    "    n_events = len(events)\n",
    "    duration = data['time'][-1] - data['time'][0]\n",
    "    rate_per_min = (n_events / duration) * 60\n",
    "    \n",
    "    # Event characteristics\n",
    "    durations_ms = [e['duration_ms'] for e in events]\n",
    "    peak_scores = [e['peak_score'] for e in events]\n",
    "    peak_accs = [e['peak_acc'] for e in events]\n",
    "    peak_gyros = [e['peak_gyro'] for e in events]\n",
    "    \n",
    "    # Inter-event intervals\n",
    "    if n_events > 1:\n",
    "        event_times = [e['peak_time'] for e in events]\n",
    "        ieis = np.diff(event_times)\n",
    "        median_iei = np.median(ieis)\n",
    "        mean_iei = np.mean(ieis)\n",
    "    else:\n",
    "        median_iei = mean_iei = 0\n",
    "    \n",
    "    print(f\"\\n=== EVENT ANALYSIS ===\")\n",
    "    print(f\"Total events: {n_events}\")\n",
    "    print(f\"Recording duration: {duration:.2f} s\")\n",
    "    print(f\"Event rate: {rate_per_min:.1f} events/min\")\n",
    "    print(f\"\")\n",
    "    print(f\"Duration statistics:\")\n",
    "    print(f\"  Median: {np.median(durations_ms):.1f} ms\")\n",
    "    print(f\"  Range: {np.min(durations_ms):.1f} - {np.max(durations_ms):.1f} ms\")\n",
    "    print(f\"\")\n",
    "    print(f\"Peak acceleration:\")\n",
    "    print(f\"  Median: {np.median(peak_accs):.3f} g\")\n",
    "    print(f\"  Range: {np.min(peak_accs):.3f} - {np.max(peak_accs):.3f} g\")\n",
    "    print(f\"\")\n",
    "    print(f\"Peak gyroscope:\")\n",
    "    print(f\"  Median: {np.median(peak_gyros):.3f} rad/s\")\n",
    "    print(f\"  Range: {np.min(peak_gyros):.3f} - {np.max(peak_gyros):.3f} rad/s\")\n",
    "    \n",
    "    if n_events > 1:\n",
    "        print(f\"\")\n",
    "        print(f\"Inter-event intervals:\")\n",
    "        print(f\"  Median: {median_iei:.3f} s ({60/median_iei:.1f}/min)\")\n",
    "        print(f\"  Mean: {mean_iei:.3f} s ({60/mean_iei:.1f}/min)\")\n",
    "    \n",
    "    # Gate compliance\n",
    "    acc_compliant = sum(1 for e in events if e['peak_acc'] >= detector.acc_gate)\n",
    "    gyro_compliant = sum(1 for e in events if e['peak_gyro'] >= detector.gyro_gate)\n",
    "    both_compliant = sum(1 for e in events if e['peak_acc'] >= detector.acc_gate and e['peak_gyro'] >= detector.gyro_gate)\n",
    "    \n",
    "    print(f\"\")\n",
    "    print(f\"Gate compliance:\")\n",
    "    print(f\"  Acceleration ≥ {detector.acc_gate:.3f}g: {acc_compliant}/{n_events} ({100*acc_compliant/n_events:.1f}%)\")\n",
    "    print(f\"  Gyroscope ≥ {detector.gyro_gate:.3f}rad/s: {gyro_compliant}/{n_events} ({100*gyro_compliant/n_events:.1f}%)\")\n",
    "    print(f\"  Both gates: {both_compliant}/{n_events} ({100*both_compliant/n_events:.1f}%)\")\n",
    "\n",
    "# Visualize results\n",
    "plot_detection_results(data, processed, events, threshold)\n",
    "\n",
    "# Analyze events\n",
    "analyze_events(events, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning Interface\n",
    "\n",
    "Interactive parameter tuning for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_parameters(acc_gate_range=[0.02, 0.06], gyro_gate_range=[0.1, 0.25], \n",
    "                   threshold_k_range=[5, 9], refractory_range=[150, 350]):\n",
    "    \"\"\"Test different parameter combinations and compare results\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Test parameter grid\n",
    "    acc_gates = np.linspace(acc_gate_range[0], acc_gate_range[1], 3)\n",
    "    gyro_gates = np.linspace(gyro_gate_range[0], gyro_gate_range[1], 3)\n",
    "    threshold_ks = np.linspace(threshold_k_range[0], threshold_k_range[1], 3)\n",
    "    refractories = np.linspace(refractory_range[0], refractory_range[1], 3)\n",
    "    \n",
    "    print(\"Parameter tuning in progress...\")\n",
    "    \n",
    "    for acc_gate in acc_gates:\n",
    "        for gyro_gate in gyro_gates:\n",
    "            for threshold_k in threshold_ks:\n",
    "                for refractory_ms in refractories:\n",
    "                    # Create detector with these parameters\n",
    "                    test_detector = PinchDetector(\n",
    "                        fs=data['fs'],\n",
    "                        acc_gate=acc_gate,\n",
    "                        gyro_gate=gyro_gate,\n",
    "                        threshold_k=threshold_k,\n",
    "                        refractory_ms=refractory_ms\n",
    "                    )\n",
    "                    \n",
    "                    # Detect events\n",
    "                    test_events, _ = test_detector.detect_events(processed)\n",
    "                    \n",
    "                    # Store results\n",
    "                    results.append({\n",
    "                        'acc_gate': acc_gate,\n",
    "                        'gyro_gate': gyro_gate,\n",
    "                        'threshold_k': threshold_k,\n",
    "                        'refractory_ms': refractory_ms,\n",
    "                        'n_events': len(test_events),\n",
    "                        'events_per_min': (len(test_events) / (data['time'][-1] - data['time'][0])) * 60\n",
    "                    })\n",
    "    \n",
    "    # Convert to DataFrame for analysis\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    print(f\"\\nTested {len(results)} parameter combinations\")\n",
    "    print(f\"Event count range: {df_results['n_events'].min():.0f} - {df_results['n_events'].max():.0f}\")\n",
    "    print(f\"Event rate range: {df_results['events_per_min'].min():.1f} - {df_results['events_per_min'].max():.1f} events/min\")\n",
    "    \n",
    "    # Find optimal parameters (closest to expected ~60 events/min from analysis)\n",
    "    target_rate = 60  # events per minute from analysis\n",
    "    df_results['rate_error'] = np.abs(df_results['events_per_min'] - target_rate)\n",
    "    optimal_idx = df_results['rate_error'].idxmin()\n",
    "    optimal_params = df_results.iloc[optimal_idx]\n",
    "    \n",
    "    print(f\"\\n=== OPTIMAL PARAMETERS (closest to {target_rate} events/min) ===\")\n",
    "    print(f\"Acceleration gate: {optimal_params['acc_gate']:.3f} g\")\n",
    "    print(f\"Gyroscope gate: {optimal_params['gyro_gate']:.3f} rad/s\")\n",
    "    print(f\"Threshold multiplier: {optimal_params['threshold_k']:.1f}\")\n",
    "    print(f\"Refractory period: {optimal_params['refractory_ms']:.0f} ms\")\n",
    "    print(f\"Resulting rate: {optimal_params['events_per_min']:.1f} events/min ({optimal_params['n_events']:.0f} events)\")\n",
    "    \n",
    "    return df_results, optimal_params\n",
    "\n",
    "# Run parameter tuning\n",
    "tuning_results, optimal_params = tune_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results and Event Candidates\n",
    "\n",
    "Export detected events for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_events(events, data, filename=\"pinch_events_v2.csv\"):\n",
    "    \"\"\"Export detected events to CSV for analysis\"\"\"\n",
    "    if not events:\n",
    "        print(\"No events to export\")\n",
    "        return\n",
    "    \n",
    "    # Create DataFrame\n",
    "    event_data = []\n",
    "    for i, event in enumerate(events):\n",
    "        event_data.append({\n",
    "            'event_id': i + 1,\n",
    "            'peak_time': event['peak_time'],\n",
    "            'peak_idx': event['peak_idx'],\n",
    "            'duration_ms': event['duration_ms'],\n",
    "            'peak_score': event['peak_score'],\n",
    "            'peak_acceleration': event['peak_acc'],\n",
    "            'peak_gyroscope': event['peak_gyro'],\n",
    "            'threshold_at_peak': event['threshold_at_peak'],\n",
    "            'start_idx': event['start_idx'],\n",
    "            'end_idx': event['end_idx']\n",
    "        })\n",
    "    \n",
    "    df_events = pd.DataFrame(event_data)\n",
    "    \n",
    "    # Add inter-event intervals\n",
    "    df_events['inter_event_interval'] = df_events['peak_time'].diff()\n",
    "    \n",
    "    # Save to CSV\n",
    "    df_events.to_csv(filename, index=False)\n",
    "    print(f\"Exported {len(events)} events to {filename}\")\n",
    "    \n",
    "    return df_events\n",
    "\n",
    "def create_summary_report(events, data, processed):\n",
    "    \"\"\"Create comprehensive summary report\"\"\"\n",
    "    duration = data['time'][-1] - data['time'][0]\n",
    "    n_events = len(events)\n",
    "    \n",
    "    report = f\"\"\"\n",
    "=== PINCH DETECTION V2 SUMMARY REPORT ===\n",
    "\n",
    "Algorithm: Robust Z-Score Fusion with Adaptive Thresholding\n",
    "Data file: WristMotion.csv\n",
    "Recording duration: {duration:.2f} seconds\n",
    "Sampling rate: {data['fs']:.1f} Hz\n",
    "Total samples: {len(data['time'])}\n",
    "\n",
    "DETECTION PARAMETERS:\n",
    "- Acceleration gate: {detector.acc_gate:.3f} g\n",
    "- Gyroscope gate: {detector.gyro_gate:.3f} rad/s\n",
    "- Threshold method: {detector.threshold_method} (k={detector.threshold_k})\n",
    "- Refractory period: {detector.refractory_samples/data['fs']*1000:.0f} ms\n",
    "- Duration constraints: {detector.min_duration_samples/data['fs']*1000:.0f}-{detector.max_duration_samples/data['fs']*1000:.0f} ms\n",
    "\n",
    "DETECTION RESULTS:\n",
    "- Total events detected: {n_events}\n",
    "- Detection rate: {(n_events/duration)*60:.1f} events/minute\n",
    "\"\"\"\n",
    "    \n",
    "    if events:\n",
    "        durations_ms = [e['duration_ms'] for e in events]\n",
    "        peak_accs = [e['peak_acc'] for e in events]\n",
    "        peak_gyros = [e['peak_gyro'] for e in events]\n",
    "        \n",
    "        report += f\"\"\"\n",
    "EVENT CHARACTERISTICS:\n",
    "- Median duration: {np.median(durations_ms):.1f} ms\n",
    "- Duration range: {np.min(durations_ms):.1f} - {np.max(durations_ms):.1f} ms\n",
    "- Median peak acceleration: {np.median(peak_accs):.3f} g\n",
    "- Acceleration range: {np.min(peak_accs):.3f} - {np.max(peak_accs):.3f} g\n",
    "- Median peak gyroscope: {np.median(peak_gyros):.3f} rad/s\n",
    "- Gyroscope range: {np.min(peak_gyros):.3f} - {np.max(peak_gyros):.3f} rad/s\n",
    "\"\"\"\n",
    "        \n",
    "        if n_events > 1:\n",
    "            event_times = [e['peak_time'] for e in events]\n",
    "            ieis = np.diff(event_times)\n",
    "            report += f\"\"\"\n",
    "INTER-EVENT INTERVALS:\n",
    "- Median IEI: {np.median(ieis):.3f} s ({60/np.median(ieis):.1f}/min)\n",
    "- Mean IEI: {np.mean(ieis):.3f} s ({60/np.mean(ieis):.1f}/min)\n",
    "- IEI range: {np.min(ieis):.3f} - {np.max(ieis):.3f} s\n",
    "\"\"\"\n",
    "    \n",
    "    print(report)\n",
    "    return report\n",
    "\n",
    "# Export results\n",
    "exported_events = export_events(events, data)\n",
    "summary_report = create_summary_report(events, data, processed)\n",
    "\n",
    "# Display first few events\n",
    "if not exported_events.empty:\n",
    "    print(\"\\n=== FIRST 5 DETECTED EVENTS ===\")\n",
    "    print(exported_events.head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time Implementation Notes\n",
    "\n",
    "For watchOS implementation:\n",
    "\n",
    "### Core Motion Setup\n",
    "```swift\n",
    "// Use CMDeviceMotion for already-processed signals\n",
    "motionManager.deviceMotionUpdateInterval = 0.01 // 100 Hz\n",
    "motionManager.showsDeviceMovementDisplay = true\n",
    "```\n",
    "\n",
    "### Key Algorithm Components\n",
    "1. **Sliding window statistics** (2-4 second windows)\n",
    "2. **Integer-optimized math** where possible\n",
    "3. **Minimal memory footprint** (O(window_size) storage)\n",
    "4. **Real-time robust statistics** (running median/MAD)\n",
    "\n",
    "### Performance Targets\n",
    "- **Latency**: <200ms detection-to-feedback\n",
    "- **Accuracy**: >85% precision/recall\n",
    "- **Battery**: Compatible with workout session duration\n",
    "\n",
    "### Calibration Workflow\n",
    "1. **Initial setup**: 30-45s of deliberate pinches\n",
    "2. **Adaptive thresholds**: Based on user's typical signal levels\n",
    "3. **Refractory tuning**: Based on user's typical pace\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
